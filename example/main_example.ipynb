{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from probabilistic_covshift.constants.automl_constants import AutoMLConfig\n",
    "from probabilistic_covshift.constants.automl_constants import H2OServerInfo\n",
    "from probabilistic_covshift.constants.main_constants import OriginFeatures, WeightFeatures\n",
    "from probabilistic_covshift.probabilistic_classification_covshift import ProbabilisticClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('main').master('local[4]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = spark.createDataFrame([\n",
    "    ('38.9', 40.0, 55, 10.0), ('88.9', 50.0, 15, 20.0),\n",
    "    ('38.9', 50.0, 15, 10.0), ('48.9', 40.0, 55, 20.0),\n",
    "    ('38.9', 40.0, 55, 10.0), ('98.9', 50.0, 15, 20.0),\n",
    "    ('88.9', 50.0, 15, 20.0), ('18.9', 40.0, 55, 30.0),\n",
    "    ('48.9', 40.0, 55, 20.0), ('58.9', 50.0, 15, 30.0),\n",
    "    ('98.9', 50.0, 15, 20.0), ('38.9', 40.0, 55, 10.0),\n",
    "    ('18.9', 40.0, 55, 30.0), ('38.9', 50.0, 15, 10.0),\n",
    "    ('58.9', 50.0, 15, 30.0), ('38.9', 40.0, 55, 10.0),\n",
    "    ('38.9', 40.0, 55, 10.0), ('88.9', 50.0, 15, 20.0),\n",
    "    ('38.9', 50.0, 15, 10.0), ('48.9', 40.0, 55, 20.0),\n",
    "    ('38.9', 40.0, 55, 10.0), ('98.9', 50.0, 15, 20.0),\n",
    "    ('88.9', 50.0, 15, 20.0), ('18.9', 40.0, 55, 30.0),\n",
    "    ('48.9', 40.0, 55, 20.0), ('58.9', 50.0, 15, 30.0),\n",
    "    ('98.9', 50.0, 15, 20.0), ('38.9', 40.0, 55, 10.0),\n",
    "    ('18.9', 40.0, 55, 30.0), ('38.9', 50.0, 15, 10.0),\n",
    "    ('58.9', 50.0, 15, 30.0), ('38.9', 40.0, 55, 10.0)],\n",
    "    ['col_a', 'col_b', 'col_c', 'col_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = spark.createDataFrame([\n",
    "    ('18.9', 40.0, 95, 10.0), ('38.9', 50.0, 15, 20.0),\n",
    "    ('18.9', 50.0, 95, 10.0), ('38.9', 40.0, 55, 20.0),\n",
    "    ('18.9', 40.0, 95, 10.0), ('38.9', 50.0, 15, 20.0),\n",
    "    ('18.9', 50.0, 95, 30.0), ('38.9', 40.0, 55, 30.0),\n",
    "    ('18.9', 40.0, 95, 30.0), ('38.9', 50.0, 15, 30.0),\n",
    "    ('38.9', 50.0, 95, 30.0), ('18.9', 40.0, 55, 10.0),\n",
    "    ('38.9', 40.0, 95, 30.0), ('18.9', 50.0, 15, 10.0),\n",
    "    ('38.9', 50.0, 95, 30.0), ('18.9', 40.0, 55, 10.0),\n",
    "    ('38.9', 40.0, 55, 30.0), ('58.9', 50.0, 15, 20.0),\n",
    "    ('38.9', 50.0, 15, 30.0), ('58.9', 40.0, 55, 20.0),\n",
    "    ('38.9', 40.0, 55, 30.0), ('58.9', 50.0, 15, 20.0),\n",
    "    ('58.9', 50.0, 15, 30.0), ('58.9', 40.0, 55, 30.0),\n",
    "    ('58.9', 40.0, 55, 30.0), ('58.9', 50.0, 15, 30.0),\n",
    "    ('58.9', 50.0, 15, 30.0), ('58.9', 40.0, 55, 10.0),\n",
    "    ('58.9', 40.0, 55, 30.0), ('58.9', 50.0, 15, 10.0),\n",
    "    ('58.9', 50.0, 15, 30.0), ('58.9', 40.0, 55, 10.0)],\n",
    "    ['col_a', 'col_b', 'col_c', 'col_d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    AutoMLConfig.DATA: {\n",
    "        AutoMLConfig.CATEGORICAL_VARIABLES: [\n",
    "            'col_a'\n",
    "        ],\n",
    "        AutoMLConfig.LABEL_COL: 'col_d',\n",
    "        AutoMLConfig.ORIGIN_COL: OriginFeatures.ORIGIN,\n",
    "        AutoMLConfig.WEIGHT_COL: WeightFeatures.WEIGHT,\n",
    "        AutoMLConfig.BASE_TABLE_PATH: 'data/base_table.parquet',\n",
    "        AutoMLConfig.WEIGHT_PATH: 'data/weight.csv'\n",
    "    },\n",
    "    AutoMLConfig.SERVER_CONN_INFO: {\n",
    "        H2OServerInfo.IP: 'localhost',\n",
    "        H2OServerInfo.PORT: '54321'\n",
    "    },\n",
    "    AutoMLConfig.CROSS_VAL: {\n",
    "        AutoMLConfig.FOLD_COL: \"fold\",\n",
    "        AutoMLConfig.NFOLDS: 8,\n",
    "    },\n",
    "    AutoMLConfig.MODELING: {\n",
    "        AutoMLConfig.MAX_RUNTIME_SECS: 3600,\n",
    "        AutoMLConfig.MAX_MODELS: 10,\n",
    "        AutoMLConfig.STOPPING_METRIC: 'logloss',\n",
    "        AutoMLConfig.SORT_METRIC: 'logloss'\n",
    "    },\n",
    "    AutoMLConfig.EXCLUDE_ALGOS: [\n",
    "        \"StackedEnsemble\",\n",
    "        \"DeepLearning\"\n",
    "    ],\n",
    "    AutoMLConfig.MODEL: {\n",
    "        AutoMLConfig.BEST_MODEL_PATH: 'data/model/'\n",
    "    },\n",
    "    AutoMLConfig.SEED: 23\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc = ProbabilisticClassification(source_df, target_df, conf)\n",
    "pc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append the weight to the base table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_frame_df = spark.read.parquet(conf[AutoMLConfig.DATA][AutoMLConfig.BASE_TABLE_PATH])\\\n",
    "                     .drop(conf[AutoMLConfig.DATA][AutoMLConfig.ORIGIN_COL])\n",
    "base_frame_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = spark.read.csv(conf[AutoMLConfig.DATA][AutoMLConfig.WEIGHT_PATH], header=True)\n",
    "weight_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_base_frame_df = base_frame_df.join(weight_df, how='left', on='row_id').drop('row_id')\n",
    "weighted_base_frame_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
